{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing HDFS\n",
    "Using magic\n",
    "\n",
    "Create input folder on HDFS if not exists\n",
    "\n",
    "Copy from data from local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment Stage 2: Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/big-data-realestate-master/scripts\n",
      "\n",
      "put: `/tmp/rs_input/raw.csv': File exists\n",
      "\n",
      "\n",
      "Found 1 items\n",
      "\n",
      "\n",
      "-rwxrwxrwx   1 1000 staff    5018236 2020-06-07 06:53 /tmp/rs_input/raw.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "! hadoop fs -mkdir -p  /tmp/rs_input\n",
    "! hadoop fs -put   -p  ./../data-raw/Melbourne_housing_FULL.csv             /tmp/rs_input/raw.csv\n",
    "! hadoop fs -ls        /tmp/rs_input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Check Spark Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res59: String =\n",
       "spark.app.id=local-1591535816132\n",
       "spark.app.name=spylon-kernel\n",
       "spark.driver.host=a56a95a92af2\n",
       "spark.driver.port=40185\n",
       "spark.executor.id=driver\n",
       "spark.master=local[*]\n",
       "spark.rdd.compress=True\n",
       "spark.repl.class.outputDir=/tmp/tmpebateiix\n",
       "spark.repl.class.uri=spark://a56a95a92af2:40185/classes\n",
       "spark.serializer.objectStreamReset=100\n",
       "spark.submit.deployMode=client\n",
       "spark.ui.showConsoleProgress=true\n"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf.toDebugString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read  file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_raw: org.apache.spark.sql.DataFrame = [Suburb: string, Address: string ... 19 more fields]\n"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//load raw into df\n",
    "val df_raw = spark\n",
    "    .read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(\"hdfs://localhost:9000/tmp/rs_input/raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res60: Long = 34857\n"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_working: org.apache.spark.sql.DataFrame = [Price: string, MethodOfSale: string ... 11 more fields]\n",
       "df_working: org.apache.spark.sql.DataFrame = [Price: string, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//only select columns we need now\n",
    "var df_working= df_raw.select(\"Price\",\n",
    "                          \"Method\",\n",
    "                          \"Type\",\n",
    "                          \"Distance\",\n",
    "                          \"Rooms\",\n",
    "                          \"Bathroom\",\n",
    "                          \"Car\",\n",
    "                          \"Landsize\",\n",
    "                          \"Lattitude\",\n",
    "                          \"Longtitude\",    \n",
    "                          \"Suburb\",\n",
    "                          \"Address\",\n",
    "                          \"Date\")\n",
    "\n",
    "\n",
    "//add meaningful to column names\n",
    "df_working = df_working.withColumnRenamed(\"Method\",\"MethodOfSale\")\n",
    "    .withColumnRenamed(\"Distance\",\"DistanceFromCBD\")\n",
    "    .withColumnRenamed(\"Type\",\"PropertyType\")\n",
    "    .withColumnRenamed(\"Lattitude\",\"Latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out  \"#N/A\" records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_working: org.apache.spark.sql.DataFrame = [Price: string, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//when profiling there are a number of columns with a \"#N/A\" which need to be removed\n",
    "df_working = df_working.filter($\"DistanceFromCBD\" =!= \"#N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change type of columns \"Price\", \"DistanceFromCBD\" & \"Landsize\" to Double, \"Rooms\", \"Bathroom\", \"Car\" to Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_working: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_working = df_working.withColumn(\"Price\",col(\"Price\").cast(\"Double\"))\n",
    "    .withColumn(\"Rooms\",col(\"Rooms\").cast(\"Int\"))\n",
    "    .withColumn(\"DistanceFromCBD\",col(\"DistanceFromCBD\").cast(\"Double\"))\n",
    "    .withColumn(\"Bathroom\",col(\"Bathroom\").cast(\"Int\"))\n",
    "    .withColumn(\"Car\",col(\"Car\").cast(\"Int\"))\n",
    "    .withColumn(\"Landsize\",col(\"Landsize\").cast(\"Double\"))\n",
    "    .withColumn(\"Latitude\",col(\"Latitude\").cast(\"Double\"))\n",
    "    .withColumn(\"Longtitude\",col(\"Longtitude\").cast(\"Double\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make First Letter of Suburb Upper Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_working: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// make first letter of suburb upper case\n",
    "df_working= df_working.withColumn(\"Suburb\", initcap(col(\"Suburb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Address on Street and Suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           Address|\n",
      "+------------------+\n",
      "|     68 Studley St|\n",
      "|      85 Turner St|\n",
      "|   25 Bloomburg St|\n",
      "|18/659 Victoria St|\n",
      "|      5 Charles St|\n",
      "|  40 Federation La|\n",
      "|       55a Park St|\n",
      "|      16 Maugie St|\n",
      "|      53 Turner St|\n",
      "|      99 Turner St|\n",
      "+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_working.select(\"Address\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_working: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//split address on Street name and Suffix\n",
    "df_working = df_working.withColumn(\"StreetName\",concat(split(col(\"Address\"),\" \").getItem(1)\n",
    "                                   , lit(\" \"),split(col(\"Address\"),\" \").getItem(2))).drop(\"Address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|   StreetName|\n",
      "+-------------+\n",
      "|   Studley St|\n",
      "|    Turner St|\n",
      "| Bloomburg St|\n",
      "|  Victoria St|\n",
      "|   Charles St|\n",
      "|Federation La|\n",
      "|      Park St|\n",
      "|    Maugie St|\n",
      "|    Turner St|\n",
      "|    Turner St|\n",
      "+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_working.select(\"StreetName\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make First Letter of Street upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_working: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// make first letter of Street upper case\n",
    "df_working= df_working.withColumn(\"StreetName\", initcap(col(\"StreetName\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Property Type to upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_working: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_working = df_working.withColumn(\"PropertyType\", upper(col(\"PropertyType\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Bad Landsize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_working: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//drop all properties with land area less than 12 sqm \n",
    "df_working = df_working.filter(!($\"Landsize\"<12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_working: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//drop rows where type = h and landsize < 50 sqm\n",
    "df_working = df_working.filter(!($\"Landsize\"<50 && $\"PropertyType\"===1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_not_null: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_not_null = df_working.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Price: double (nullable = true)\n",
      " |-- MethodOfSale: string (nullable = true)\n",
      " |-- PropertyType: string (nullable = true)\n",
      " |-- DistanceFromCBD: double (nullable = true)\n",
      " |-- Rooms: integer (nullable = true)\n",
      " |-- Bathroom: integer (nullable = true)\n",
      " |-- Car: integer (nullable = true)\n",
      " |-- Landsize: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longtitude: double (nullable = true)\n",
      " |-- Suburb: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- StreetName: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_not_null.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Down Clean Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hadoop fs -mkdir -p /tmp/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_output: Unit = ()\n"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_output = df_not_null.coalesce(1)\n",
    "   .write\n",
    "   .format(\"csv\")\n",
    "   .option(\"header\",\"true\")\n",
    "   .mode(\"overwrite\").option(\"sep\",\",\")\n",
    "   .save(\"hdfs://localhost:9000/tmp/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Clean Data to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyToLocal: `./../data-clean/cleanMelbourneData.csv': File exists\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -mkdir -p /tmp/output\n",
    "! hadoop fs -copyToLocal /tmp/output/\\*.csv ./../data-clean/cleanMelbourneData.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment Stage 3: Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_clean: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// use the set wrangled from \n",
    "var df_clean = df_not_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Price: double (nullable = true)\n",
      " |-- MethodOfSale: string (nullable = true)\n",
      " |-- PropertyType: string (nullable = true)\n",
      " |-- DistanceFromCBD: double (nullable = true)\n",
      " |-- Rooms: integer (nullable = true)\n",
      " |-- Bathroom: integer (nullable = true)\n",
      " |-- Car: integer (nullable = true)\n",
      " |-- Landsize: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longtitude: double (nullable = true)\n",
      " |-- Suburb: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- StreetName: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "res64: Long = 15710\n"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.cache()\n",
    "df_clean.printSchema()\n",
    "df_clean.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct vectors from attributes\n",
    "#### Transform Sale Date into a numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_clean: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_clean.withColumn(\"Date\",unix_timestamp($\"Date\", \"dd/mm/yyyy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set StringIndexer for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.{FeatureHasher, StandardScaler, OneHotEncoder, VectorAssembler}\n",
       "import org.apache.spark.ml.feature.{OneHotEncoderEstimator, StringIndexer, VectorIndexer}\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "suburbIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_120e61b8b96e\n",
       "streetNameIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_ed21cf2cda89\n",
       "propertyTypeIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_9b0305595738\n",
       "methodOfSaleIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_5459a65fbd5f\n",
       "categoricalFeatureColumnNames: Array[String] = Array(MethodOfSaleIndex, PropertyTypeIndex, SuburbIndex, StreetNameIndex)\n",
       "featureColumnNames: Array[String] = Array(MethodOfSale, PropertyType, Suburb, StreetName, DistanceFromCBD, Rooms,..."
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{FeatureHasher,StandardScaler,OneHotEncoder,VectorAssembler}\n",
    "import org.apache.spark.ml.feature.{OneHotEncoderEstimator,StringIndexer,VectorIndexer}\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "//define string indexers on categorical values\n",
    "val suburbIndexer = new StringIndexer()\n",
    "    .setInputCol(\"Suburb\")\n",
    "    .setOutputCol(\"SuburbIndex\")\n",
    "    .setHandleInvalid(\"keep\")\n",
    "\n",
    "val streetNameIndexer = new StringIndexer()\n",
    "    .setInputCol(\"StreetName\")\n",
    "    .setOutputCol(\"StreetNameIndex\")\n",
    "    .setHandleInvalid(\"keep\")\n",
    "\n",
    "//define string indexers\n",
    "val propertyTypeIndexer = new StringIndexer()\n",
    "    .setInputCol(\"PropertyType\")\n",
    "    .setOutputCol(\"PropertyTypeIndex\")\n",
    "    .setHandleInvalid(\"keep\")\n",
    "\n",
    "val methodOfSaleIndexer = new StringIndexer()\n",
    "    .setInputCol(\"MethodOfSale\")\n",
    "    .setOutputCol(\"MethodOfSaleIndex\")\n",
    "    .setHandleInvalid(\"keep\")\n",
    "\n",
    "\n",
    "//set the categorical names\n",
    "val categoricalFeatureColumnNames= Array(\"MethodOfSaleIndex\",\n",
    "            \"PropertyTypeIndex\",\n",
    "            \"SuburbIndex\",\n",
    "            \"StreetNameIndex\")\n",
    "\n",
    "val featureColumnNames= Array(\"MethodOfSale\",\n",
    "            \"PropertyType\",\n",
    "             \"Suburb\",                 \n",
    "            \"StreetName\",\n",
    "            \"DistanceFromCBD\",\n",
    "            \"Rooms\",\n",
    "            \"Bathroom\",\n",
    "            \"Car\",\n",
    "            \"Landsize\",\n",
    "            \"Latitude\",\n",
    "            \"Longtitude\",\n",
    "            \"Date\"\n",
    "            )\n",
    "\n",
    "//define feature hasher for Linear Regressoin\n",
    "val featureHasher = new FeatureHasher()\n",
    "    .setInputCols(featureColumnNames)\n",
    "    .setCategoricalCols(categoricalFeatureColumnNames)\n",
    "    .setOutputCol(\"hashedFeatures\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set OneHotEncoder for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allEncoder: org.apache.spark.ml.feature.OneHotEncoderEstimator = oneHotEncoder_6c3afa335a00\n"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// one hot encoder\n",
    "val allEncoder = new OneHotEncoderEstimator()\n",
    "  .setInputCols(categoricalFeatureColumnNames)\n",
    "  .setOutputCols(Array(\"MethodOfSaleCategoryVec1\",\n",
    "                       \"PropertyTypeCategoryVec2\",\n",
    "                       \"SuburbIndexCategoryVec3\",\n",
    "                       \"StreetNameIndexCategoryVec4\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble the columns and column vectors into a single column - \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WithEncodedCategoricalFeatureColumnNames: Array[String] = Array(DistanceFromCBD, Rooms, Bathroom, Car, Landsize, Latitude, Longtitude, Date, MethodOfSaleCategoryVec1, PropertyTypeCategoryVec2, SuburbIndexCategoryVec3, StreetNameIndexCategoryVec4)\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_e12a44990a77\n"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val WithEncodedCategoricalFeatureColumnNames = Array(\n",
    "                    \"DistanceFromCBD\", \n",
    "                    \"Rooms\", \n",
    "                    \"Bathroom\",\n",
    "                    \"Car\", \n",
    "                    \"Landsize\", \n",
    "                    \"Latitude\", \n",
    "                    \"Longtitude\", \n",
    "                    \"Date\", \n",
    "                    \"MethodOfSaleCategoryVec1\",\n",
    "                    \"PropertyTypeCategoryVec2\",\n",
    "                    \"SuburbIndexCategoryVec3\",\n",
    "                    \"StreetNameIndexCategoryVec4\")\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "            .setInputCols(WithEncodedCategoricalFeatureColumnNames)\n",
    "            .setOutputCol(\"features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler: org.apache.spark.ml.feature.StandardScaler = stdScal_4373292efbea\n"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val scaler = new StandardScaler()\n",
    "      .setInputCol(\"features\")\n",
    "      .setOutputCol(\"scaledFeatures\")\n",
    "      .setWithStd(true).setWithMean(true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Log Transform to Price (right skewed --> 'more normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_clean: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_clean.withColumn(\"loggedPrice\", log($\"Price\").cast(\"Double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       loggedPrice|\n",
      "+------------------+\n",
      "|14.207552645740298|\n",
      "|13.849911984681606|\n",
      "|14.197365800433305|\n",
      "|13.652991628466498|\n",
      "+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.select(\"loggedPrice\").show(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|    Price|      PriceAntilog|\n",
      "+---------+------------------+\n",
      "|1480000.0|1480000.0000000007|\n",
      "|1035000.0|1034999.9999999997|\n",
      "|1465000.0|1465000.0000000005|\n",
      "| 850000.0| 849999.9999999994|\n",
      "|1600000.0| 1600000.000000001|\n",
      "| 941000.0| 940999.9999999994|\n",
      "|1876000.0|1876000.0000000012|\n",
      "|1636000.0| 1635999.999999999|\n",
      "|1097000.0|1096999.9999999995|\n",
      "|1350000.0|1350000.0000000002|\n",
      "+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//check the antilog - introduces a slight rounding error\n",
    "//could fix in future\n",
    "df_clean.withColumn(\"PriceAntilog\", exp((col(\"loggedPrice\")))).select(\"Price\",\"PriceAntilog\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into a Training and a Testing Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare raw and clean data by proportion of property type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.toDF.createOrReplaceTempView(\"df_py_raw\")\n",
    "df_clean.toDF.createOrReplaceTempView(\"df_py_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------------+---------------+-----+--------+---+--------+--------+----------+----------+----------+-------------+------------------+\n",
      "|    Price|MethodOfSale|PropertyType|DistanceFromCBD|Rooms|Bathroom|Car|Landsize|Latitude|Longtitude|    Suburb|      Date|   StreetName|       loggedPrice|\n",
      "+---------+------------+------------+---------------+-----+--------+---+--------+--------+----------+----------+----------+-------------+------------------+\n",
      "|1480000.0|           S|           H|            2.5|    2|       1|  1|   202.0|-37.7996|  144.9984|Abbotsford|1451779920|    Turner St|14.207552645740298|\n",
      "|1035000.0|           S|           H|            2.5|    2|       1|  0|   156.0|-37.8079|  144.9934|Abbotsford|1451865720| Bloomburg St|13.849911984681606|\n",
      "|1465000.0|          SP|           H|            2.5|    3|       2|  0|   134.0|-37.8093|  144.9944|Abbotsford|1483488180|   Charles St|14.197365800433305|\n",
      "| 850000.0|          PI|           H|            2.5|    3|       2|  1|    94.0|-37.7969|  144.9969|Abbotsford|1483488180|Federation La|13.652991628466498|\n",
      "|1600000.0|          VB|           H|            2.5|    4|       1|  2|   120.0|-37.8072|  144.9941|Abbotsford|1451865960|      Park St| 14.28551418721001|\n",
      "+---------+------------+------------+---------------+-----+--------+---+--------+--------+----------+----------+----------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "df_raw_p = spark.sql(\"select * from df_py_raw\")\n",
    "df_clean_p = spark.sql(\"select * from df_py_clean\")\n",
    "df_clean_p.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
      "\n",
      "\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
      "\n",
      "\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "\n",
      "\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "\n",
      "\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "\n",
      "\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
      "\n",
      "\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib) (1.11.0)\n",
      "\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
      "\n",
      "\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "\n",
      "\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2020.1)\n",
      "\n",
      "\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "\n",
      "\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas) (1.11.0)\n",
      "\n",
      "\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "\n",
      "\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
      "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
      "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
      "       'Longtitude', 'Regionname', 'Propertycount'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='cbfaaa97-82bb-4f0f-a6f7-3db323f30852'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook \n",
    "%%python\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_raw_pd = df_raw_p.toPandas() \n",
    "print(df_raw_pd.columns)\n",
    "\n",
    "ax = df_raw_pd.groupby(\"Type\")[\"Price\"].nunique().plot(kind=\"bar\")\n",
    "ax.set_ylabel(\"Price in (mln)\")\n",
    "ax.set_xlabel(\"Type\")\n",
    "plt.grid()\n",
    "plt.title(\"Price Distribution by Property Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='9b9d9761-3f56-484c-a67d-e2660d83959c'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook \n",
    "%%python\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_clean_pd = df_clean_p.toPandas() \n",
    "\n",
    "# H -House, T -Townhouse, U- Unit, \n",
    "ax = df_clean_pd.groupby(\"PropertyType\")[\"Price\"].nunique().plot(kind=\"bar\")\n",
    "ax.set_ylabel(\"Price in (mln)\")\n",
    "ax.set_xlabel(\"Propetry Type\")\n",
    "plt.grid()\n",
    "plt.title(\"Price Distribution by Property Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train/Test Balanced on Property Type in Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.VectorAssembler\n",
       "import org.apache.spark.sql.DataFrame\n",
       "import org.apache.spark.sql.functions._\n",
       "train_test_split: (data: org.apache.spark.sql.DataFrame, fraction: Double)(org.apache.spark.sql.Dataset[org.apache.spark.sql.Row], org.apache.spark.sql.Dataset[org.apache.spark.sql.Row])\n"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "//stratafied sample on propertype type\n",
    "//original random sample may have been skewing the model\n",
    "//used proper type as the prices vary wildly based on the type \n",
    "\n",
    "//idea is split into training and testing - then stratify the training set so its balanced.\n",
    "def train_test_split(data: DataFrame, fraction: Double) = {\n",
    "    \n",
    "    //split into 80% 20%\n",
    "    var Array (train, test) = data.randomSplit(Array(0.8, 0.2), seed = 30)\n",
    "    \n",
    "    //val sample_data = data.stat.sampleBy(\"PropertyType\",data,36L)\n",
    "    val train_fractions = Map(\"H\" -> 0.8*fraction,\"T\" ->0.9*fraction, \"U\" -> 0.9*fraction)\n",
    "    val test_fractions = Map(\"H\" -> 0.8*fraction,\"T\" ->0.9*fraction, \"U\" -> 0.9*fraction)\n",
    "    \n",
    "         \n",
    "    train = train.stat.sampleBy(\"PropertyType\",train_fractions,36L)\n",
    "    test = test.stat.sampleBy(\"PropertyType\",test_fractions,36L)\n",
    "    \n",
    "     //sample from the data without train set \n",
    "     (train, test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Price: double, MethodOfSale: string ... 12 more fields]\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Price: double, MethodOfSale: string ... 12 more fields]\n",
       "train_sample: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Price: double, MethodOfSale: string ... 12 more fields]\n",
       "test_sample: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Price: double, MethodOfSale: string ... 12 more fields]\n",
       "res68: test_sample.type = [Price: double, MethodOfSale: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//full data set\n",
    "val (train, test) = train_test_split(df_clean,1)//train_test_split(test_pt,1)\n",
    "//fraction of data set for finding best model\n",
    "val (train_sample, test_sample) = train_test_split(df_clean,0.1)//train_test_split(test_pt,0.1)\n",
    "train.cache()\n",
    "test.cache()\n",
    "train_sample.cache()\n",
    "test_sample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res69: Long = 10195\n"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res70: Long = 2548\n"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res71: Long = 1043\n"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res72: Long = 230\n"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Apply Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Execution Time for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getExecutionTime: (start: Long, end: Long)Long\n"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//function for getting execution time from start and end times\n",
    "def getExecutionTime(start: Long , end : Long) = {\n",
    "    val duration:Long = (end - start)/1000\n",
    "    duration\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run LR Model with Default Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res73: Array[String] = Array(Price, MethodOfSale, PropertyType, DistanceFromCBD, Rooms, Bathroom, Car, Landsize, Latitude, Longtitude, Suburb, Date, StreetName, loggedPrice)\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was executed 7 s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.LinearRegression\n",
       "import org.apache.spark.ml.Pipeline\n",
       "startTimeMillis: Long = 1591782492296\n",
       "lr: org.apache.spark.ml.regression.LinearRegression = linReg_1496588f36da\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_c93a026f6bc2\n",
       "result: org.apache.spark.sql.DataFrame = [MethodOfSale: string, PropertyType: string ... 17 more fields]\n",
       "endTimeMillis: Long = 1591782499737\n"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.Pipeline\n",
    "val startTimeMillis = System.currentTimeMillis()\n",
    "\n",
    "val lr = new LinearRegression()\n",
    "    .setLabelCol(\"loggedPrice\")\n",
    "    .setFeaturesCol(\"hashedFeatures\")\n",
    "    .setPredictionCol(\"Predicted loggedPrice\")\n",
    "    .setMaxIter(100)\n",
    "\n",
    "   val pipeline = new Pipeline()\n",
    "      .setStages(Array(suburbIndexer,\n",
    "                       streetNameIndexer,\n",
    "                       propertyTypeIndexer,\n",
    "                       methodOfSaleIndexer,\n",
    "                       featureHasher,\n",
    "                      lr))\n",
    "     \n",
    "  val result =pipeline.fit(train.drop(\"Price\")).transform(test.drop(\"Price\"))\n",
    "\n",
    "val endTimeMillis = System.currentTimeMillis()\n",
    "\n",
    "print(\"Model was executed \"\n",
    "      + getExecutionTime(startTimeMillis,endTimeMillis)+\" s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res77: Array[String] = Array(MethodOfSale, PropertyType, DistanceFromCBD, Rooms, Bathroom, Car, Landsize, Latitude, Longtitude, Suburb, Date, StreetName, loggedPrice, SuburbIndex, StreetNameIndex, PropertyTypeIndex, MethodOfSaleIndex, hashedFeatures, Predicted loggedPrice)\n"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define LR Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
       "evaluate_lr: (predictions: org.apache.spark.sql.DataFrame, metric: String)Unit\n"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "\n",
    "// define an evaluator \n",
    "def evaluate_lr ( predictions: DataFrame, metric: String) = {\n",
    "    val eval =  new RegressionEvaluator()\n",
    "       .setLabelCol(\"loggedPrice\")\n",
    "       .setPredictionCol(\"Predicted loggedPrice\")\n",
    "       .setMetricName(metric)\n",
    "println(metric.toUpperCase()\n",
    "        +\" on test data = \" + eval.evaluate(predictions))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Metrics\n",
    "\n",
    "**Mean squared error (MSE)** -- the average of squared differences between the predicted outcome and the true outcome.\n",
    "\n",
    "**R2 coefficient** -- the proportion of variance in the outcome that our model is capable of predicting based on its features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 0.26115628876579966\n"
     ]
    }
   ],
   "source": [
    "evaluate_lr(result,\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.7272906592980537\n"
     ]
    }
   ],
   "source": [
    "evaluate_lr(result,\"r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Finding the Best Model (Parameter Tuning) by Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res80: Array[String] = Array(Price, MethodOfSale, PropertyType, DistanceFromCBD, Rooms, Bathroom, Car, Landsize, Latitude, Longtitude, Suburb, Date, StreetName, loggedPrice)\n"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-10 09:48:36,310 WARN  [block-manager-slave-async-thread-pool-910] storage.BlockManager (Logging.scala:logWarning(66)) - Asked to remove block broadcast_20078, which does not exist\n",
      "2020-06-10 09:48:44,767 WARN  [block-manager-slave-async-thread-pool-907] storage.BlockManager (Logging.scala:logWarning(66)) - Asked to remove block broadcast_20379, which does not exist\n",
      "2020-06-10 09:48:54,266 WARN  [block-manager-slave-async-thread-pool-921] storage.BlockManager (Logging.scala:logWarning(66)) - Asked to remove block broadcast_20679, which does not exist\n",
      "2020-06-10 09:48:56,235 WARN  [block-manager-slave-async-thread-pool-882] storage.BlockManager (Logging.scala:logWarning(66)) - Asked to remove block broadcast_20761, which does not exist\n",
      "2020-06-10 09:49:10,160 WARN  [Executor task launch worker for task 14861] storage.BlockManager (Logging.scala:logWarning(66)) - Block rdd_49375_1 already exists on this machine; not re-adding it\n",
      "2020-06-10 09:50:04,462 WARN  [block-manager-slave-async-thread-pool-845] storage.BlockManager (Logging.scala:logWarning(66)) - Asked to remove block broadcast_23254, which does not exist\n",
      "2020-06-10 09:50:34,993 WARN  [Executor task launch worker for task 18233] storage.BlockManager (Logging.scala:logWarning(66)) - Block rdd_53665_1 already exists on this machine; not re-adding it\n",
      "2020-06-10 09:50:35,005 WARN  [Executor task launch worker for task 18232] storage.BlockManager (Logging.scala:logWarning(66)) - Block rdd_53665_0 already exists on this machine; not re-adding it\n",
      "2020-06-10 09:51:01,294 WARN  [block-manager-slave-async-thread-pool-910] storage.BlockManager (Logging.scala:logWarning(66)) - Asked to remove block broadcast_25223, which does not exist\n",
      "2020-06-10 09:51:17,666 WARN  [Executor task launch worker for task 19916] storage.BlockManager (Logging.scala:logWarning(66)) - Block rdd_55809_0 already exists on this machine; not re-adding it\n",
      "2020-06-10 09:51:24,409 WARN  [block-manager-slave-async-thread-pool-901] storage.BlockManager (Logging.scala:logWarning(66)) - Asked to remove block broadcast_26053, which does not exist\n",
      "+------------------+---------------------+\n",
      "|       loggedPrice|Predicted LoggedPrice|\n",
      "+------------------+---------------------+\n",
      "|12.128111104060462|   13.006566230775391|\n",
      "|12.911642346088676|   13.104193922893515|\n",
      "| 12.93723789327764|   13.243159071379168|\n",
      "|12.948009990259552|   13.453582954022252|\n",
      "| 12.94919975839514|   13.472039445478416|\n",
      "|13.001325049027272|   13.427678868071226|\n",
      "|13.017002861746503|   13.504588560359153|\n",
      "|13.060487973686241|   13.730218772192288|\n",
      "|13.060487973686241|   13.081690459258212|\n",
      "|13.112313041550827|   13.299733158593241|\n",
      "|13.124361380067002|   13.754120468759524|\n",
      "|13.142166004700508|   13.107603295244573|\n",
      "|13.142166004700508|   13.293615382722678|\n",
      "|13.146079904021645|   13.460884186449377|\n",
      "|13.151922179645874|   13.453690943065865|\n",
      "|13.151922179645874|   12.966163458009746|\n",
      "|13.152892582439152|   13.554967063284707|\n",
      "| 13.16158409055761|   13.594108635578678|\n",
      "|13.217673557208654|   13.684435869226249|\n",
      "|13.226723392728571|   13.469886069471514|\n",
      "+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Model was executed 219 s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.param.ParamMap\n",
       "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\n",
       "startTimeMillis: Long = 1591782507801\n",
       "lr: org.apache.spark.ml.regression.LinearRegression = linReg_9af48580401f\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_d48747f88a21\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\tlinReg_9af48580401f-elasticNetParam: 0.0,\n",
       "\tlinReg_9af48580401f-regParam: 0.0\n",
       "}, {\n",
       "\tlinReg_9af48580401f-elasticNetParam: 0.0,\n",
       "\tlinReg_9af48580401f-regParam: 0.1\n",
       "}, {\n",
       "\tlinReg_9af48580401f-elasticNetParam: 0.0,\n",
       "\tlinReg_9af48580401f-regParam: 0.5\n",
       "}, {\n",
       "\tlinReg_9af48580401f-elasticNetParam: 0.0,\n",
       "\tlinReg_9af48580401f-regParam: 1.0\n",
       "}, {\n",
       "\tlinReg_9af48580401f-elasticNetParam: 0.1,\n",
       "\tlinReg_9af48580401f-regParam: 0.0\n",
       "}, {\n",
       "\tlinReg_9af48580401f-elasticNetPa..."
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.param.ParamMap\n",
    "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\n",
    "\n",
    "\n",
    "//Creates a crossvalidator on only the LR model\n",
    "//Had some issues retreiving the params when using on pipeline\n",
    "//and the pipeline only has one estimator in it so this was easier than traversing the stages of the pipline\n",
    "\n",
    "val startTimeMillis = System.currentTimeMillis()\n",
    "\n",
    "//set LR with 100 max iter\n",
    "val lr = new LinearRegression()\n",
    "    .setLabelCol(\"loggedPrice\")\n",
    "    .setFeaturesCol(\"hashedFeatures\")\n",
    "    .setPredictionCol(\"Predicted LoggedPrice\")\n",
    "\n",
    "\n",
    "val pipeline = new Pipeline()\n",
    "    .setStages(Array(suburbIndexer,\n",
    "                    streetNameIndexer,\n",
    "                    propertyTypeIndexer,\n",
    "                    methodOfSaleIndexer,\n",
    "                    featureHasher,\n",
    "                    lr))\n",
    "     \n",
    "// We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(lr.regParam, Array(0,0.1,0.5,1))\n",
    "  .addGrid(lr.elasticNetParam, Array(0,0.1,0.5,1))\n",
    "  .build()\n",
    "\n",
    "// We now treat the model as an Estimator, wrapping it in a CrossValidator instance.\n",
    "// This will allow us to choose best params for the model\n",
    "val cv = new CrossValidator()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(new RegressionEvaluator()\n",
    "  .setLabelCol(\"loggedPrice\")\n",
    "  .setPredictionCol(\"Predicted LoggedPrice\")\n",
    "  .setMetricName(\"rmse\"))\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setNumFolds(5)  \n",
    "  .setParallelism(2)\n",
    "\n",
    "\n",
    "// Run cross-validation, and choose the best set of parameters.\n",
    "val cvModel = cv.fit(train_sample.drop(\"Price\"))\n",
    "\n",
    "// Make predictions on test documents. \n",
    "//cvModel uses the best model found.\n",
    "cvModel.transform(test_sample.drop(\"Price\"))\n",
    "  .select(\"loggedPrice\", \"Predicted LoggedPrice\")\n",
    "  .show()\n",
    "\n",
    "//print runtime\n",
    "val endTimeMillis = System.currentTimeMillis()\n",
    "\n",
    "print(\"Model was executed \"\n",
    "      + getExecutionTime(startTimeMillis,endTimeMillis)+\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res83: org.apache.spark.ml.Model[_] = pipeline_d48747f88a21\n"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = {\n",
      "\tlinReg_9af48580401f-aggregationDepth: 2,\n",
      "\tlinReg_9af48580401f-elasticNetParam: 0.1,\n",
      "\tlinReg_9af48580401f-epsilon: 1.35,\n",
      "\tlinReg_9af48580401f-featuresCol: hashedFeatures,\n",
      "\tlinReg_9af48580401f-fitIntercept: true,\n",
      "\tlinReg_9af48580401f-labelCol: loggedPrice,\n",
      "\tlinReg_9af48580401f-loss: squaredError,\n",
      "\tlinReg_9af48580401f-maxIter: 100,\n",
      "\tlinReg_9af48580401f-predictionCol: Predicted LoggedPrice,\n",
      "\tlinReg_9af48580401f-regParam: 0.1,\n",
      "\tlinReg_9af48580401f-solver: auto,\n",
      "\tlinReg_9af48580401f-standardization: true,\n",
      "\tlinReg_9af48580401f-tol: 1.0E-6\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.PipelineModel\n",
       "import org.apache.spark.ml.regression.LinearRegressionModel\n",
       "bestModel: org.apache.spark.ml.Model[_] = pipeline_d48747f88a21\n",
       "bestLRModel: org.apache.spark.ml.regression.LinearRegressionModel = linReg_9af48580401f\n"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.PipelineModel\n",
    "import org.apache.spark.ml.regression.LinearRegressionModel\n",
    "\n",
    "//print out the params used for the best model\n",
    "val bestModel = cvModel.bestModel\n",
    "val bestLRModel = bestModel.asInstanceOf[PipelineModel].stages.last.asInstanceOf[LinearRegressionModel]\n",
    "println(\"params = \" + bestLRModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define LR Pipeline for the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr_best: org.apache.spark.ml.regression.LinearRegression = linReg_7cffb85e3f5e\n",
       "lrStages: Array[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.util.DefaultParamsWritable}}] = Array(strIdx_120e61b8b96e, strIdx_ed21cf2cda89, strIdx_9b0305595738, strIdx_5459a65fbd5f, featureHasher_804ae9fd5d02, linReg_7cffb85e3f5e)\n"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr_best = new LinearRegression()\n",
    "  .setLabelCol(\"loggedPrice\")\n",
    "  .setPredictionCol(\"Predicted LoggedPrice\")\n",
    "  .setFeaturesCol(\"hashedFeatures\")\n",
    "  .setRegParam(bestLRModel.getRegParam)\n",
    "  .setMaxIter(bestLRModel.getMaxIter)\n",
    "\n",
    "\n",
    "\n",
    "val lrStages = Array(suburbIndexer,\n",
    "                    streetNameIndexer,\n",
    "                    propertyTypeIndexer,\n",
    "                    methodOfSaleIndexer,\n",
    "                    featureHasher,\n",
    "                    lr_best\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline was executed 4"
     ]
    },
    {
     "data": {
      "text/plain": [
       "startTimeMillis: Long = 1591782756743\n",
       "lrPipe: org.apache.spark.ml.Pipeline = pipeline_cc23364201be\n",
       "lrModel: org.apache.spark.ml.PipelineModel = pipeline_cc23364201be\n",
       "predictions: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 18 more fields]\n",
       "endTimeMillis: Long = 1591782761496\n"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val startTimeMillis = System.currentTimeMillis()\n",
    "\n",
    "//define a pipleine\n",
    "val lrPipe = new Pipeline().setStages(lrStages)\n",
    "\n",
    "// We fit our DataFrame into the pipeline to generate a model\n",
    "// pass best ParamMap from cross validation\n",
    "val lrModel = lrPipe.fit(train)\n",
    "\n",
    "\n",
    "// Make predictions using the model and the test data\n",
    "// pass best ParamMap from cross validation\n",
    "val predictions = lrModel.transform(test)\n",
    "\n",
    "val endTimeMillis = System.currentTimeMillis()\n",
    "\n",
    "print(\"Pipeline was executed \"\n",
    "      + getExecutionTime(startTimeMillis,endTimeMillis))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res86: Array[String] = Array(Price, MethodOfSale, PropertyType, DistanceFromCBD, Rooms, Bathroom, Car, Landsize, Latitude, Longtitude, Suburb, Date, StreetName, loggedPrice, SuburbIndex, StreetNameIndex, PropertyTypeIndex, MethodOfSaleIndex, hashedFeatures, Predicted LoggedPrice)\n"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undo the Log Transformn on the Prediciton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   Predicted Price|\n",
      "+------------------+\n",
      "|309973.26734938245|\n",
      "|499984.91108261654|\n",
      "| 389039.8075579358|\n",
      "| 582436.0325127327|\n",
      "| 374381.4550044331|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "logtransformPredict: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 18 more fields]\n"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var logtransformPredict = predictions.withColumn(\"Predicted loggedPrice\",col(\"Predicted loggedPrice\").cast(\"Double\"))\n",
    "\n",
    "logtransformPredict.withColumn(\"Predicted Price\", exp((col(\"Predicted loggedPrice\")))).select(\"Predicted Price\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bestlr_predict: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 19 more fields]\n"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//inverse the log transform\n",
    "val bestlr_predict = logtransformPredict.withColumn(\"Predicted Price\", exp((col(\"Predicted loggedPrice\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|   Price|Predicted Price|\n",
      "+--------+---------------+\n",
      "|185000.0|       309973.0|\n",
      "|286000.0|       499985.0|\n",
      "|288000.0|       389040.0|\n",
      "|288000.0|       582436.0|\n",
      "|291000.0|       374381.0|\n",
      "|302500.0|       369520.0|\n",
      "|305000.0|       396064.0|\n",
      "|312000.0|       500956.0|\n",
      "|316000.0|       538981.0|\n",
      "|325000.0|       469999.0|\n",
      "|326500.0|       890847.0|\n",
      "|327000.0|       519483.0|\n",
      "|330000.0|       765815.0|\n",
      "|330000.0|       808902.0|\n",
      "|347500.0|       467650.0|\n",
      "|352000.0|       444616.0|\n",
      "|354000.0|      1111019.0|\n",
      "|355000.0|       536028.0|\n",
      "|355000.0|       652894.0|\n",
      "|360000.0|       472780.0|\n",
      "+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//finesse the output of predicted price and price to aid visual compare\n",
    "bestlr_predict.withColumn(\"Predicted Price\", round($\"Predicted Price\", 0))\n",
    "    .select(\"Price\",\"Predicted Price\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 0.25922355892456994\n"
     ]
    }
   ],
   "source": [
    "evaluate_lr(bestlr_predict,\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.7313121832404834\n"
     ]
    }
   ],
   "source": [
    "evaluate_lr(bestlr_predict,\"r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply Random Forest Regression\n",
    "\n",
    "**Build Random Forest model**\n",
    "\n",
    "Specify _numTrees, maxDepth, maxBins, featureSubsetStrategy_ and _seed_ parameters.\n",
    "\n",
    "* **numTrees** -- Number of trees in the forest\n",
    "\n",
    "* **maxDepth** -- Maximum depth of a tree. Increasing the depth makes the model more powerful, but deep trees take longer to train.\n",
    "\n",
    "* **maxBins** -- Maximum number of bins used for discretizing continuous features and for choosing how to split on features at each node.\n",
    "\n",
    "* **featureSubsetStrategy** -- Automatically select the number of features to consider for splits at each tree node\n",
    "\n",
    "* **seed** -- Use a random seed number , allowing to repeat the results\n",
    "* **MaxMemoryInMB** - Maximum memory in MB allocated to histogram aggregation.\n",
    "* **CacheNodeIds** - If FALSE, the algorithm will pass trees to executors to match instances with nodes. If TRUE, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If the number of trees is 1, then no bootstrapping is used at all. However, if the number of trees is > 1, then the bootstrapping is accomplished. Where, the parameter _featureSubsetStrategy_ signifies the number of features to be considered for splits at each node. The supported values of _featureSubsetStrategy_ are \"auto\", \"all\", \"sqrt\", \"log2\" and \"on third\". The supported numerical values, on the other hand, are $(0.0-1.0]$ and $[1-n]$. However, if _featureSubsetStrategy_ is chosen as $\"auto\"$, the algorithm chooses the best feature subset strategy automatically\n",
    "\n",
    "\n",
    "If the $numTrees == 1$, the featureSubsetStrategy is set to be \"all\". However, if the $numTrees > 1$ (i.e., forest), featureSubsetStrategy is set to be \"onethird\" for regression\n",
    "\n",
    "\n",
    "Moreover, if a real value \"n\" is in the range $(0, 1.0]$ is set, n*number_of_features is used consequently. However, if an integer value \"n\" is in the range (1, the number of features) is set, only n features are used alternatively\n",
    "\n",
    "\n",
    "The parameter _categoricalFeaturesInfo_ which is a map is used for storing arbitrary of categorical features. An entry $(n -> k)$ indicates that feature n is categorical with k categories indexed from $0: {0, 1,...,k-1}$\n",
    "The impurity criterion used for regression is “variance”. \n",
    "\n",
    "The _maxDepth_ is the maximum depth of the tree. (e.g., depth 0 means 1 leaf node, depth 1 means 1 internal node + 2 leaf nodes). However, the suggested value is 4 to get a better result\n",
    "\n",
    "\n",
    "The _maxBins_ signifies the maximum number of bins used for splitting the features; where the suggested value is 100 to get better results\n",
    "\n",
    "\n",
    "Finally, the random seed is used for bootstrapping and choosing feature subsets to avoid the random nature of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time: [R](block: => R)R\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time[R](block: => R): R = {\n",
    "  val t0 = System.nanoTime()\n",
    "  val result = block    // call-by-name\n",
    "  val t1 = System.nanoTime()\n",
    "  println(\"Elapsed time: \" + (t1 - t0)/1000000000 + \" s\")\n",
    "  result\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.RandomForestRegressor\n",
       "rf: org.apache.spark.ml.regression.RandomForestRegressor = rfr_d630f6022c53\n",
       "res31: org.apache.spark.ml.param.ParamMap =\n",
       "{\n",
       "\trfr_d630f6022c53-cacheNodeIds: true,\n",
       "\trfr_d630f6022c53-checkpointInterval: 10,\n",
       "\trfr_d630f6022c53-featureSubsetStrategy: auto,\n",
       "\trfr_d630f6022c53-featuresCol: scaledFeatures,\n",
       "\trfr_d630f6022c53-impurity: variance,\n",
       "\trfr_d630f6022c53-labelCol: Price,\n",
       "\trfr_d630f6022c53-maxBins: 32,\n",
       "\trfr_d630f6022c53-maxDepth: 5,\n",
       "\trfr_d630f6022c53-maxMemoryInMB: 512,\n",
       "\trfr_d630f6022c53-minInfoGain: 0.0,\n",
       "\trfr_d630f6022c53-minInstancesPerNode: 1,\n",
       "\trfr_d630f6022c53-numTrees: 20,\n",
       "\trfr_d630f6022c53-predictionCol: prediction,\n",
       "\trfr_d630f6022c53-seed: 36,\n",
       "\trfr_d630f6022c53-subsamplingRate: 1.0\n",
       "}\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.RandomForestRegressor\n",
    "\n",
    "val rf = new RandomForestRegressor()\n",
    "  .setSeed(36L)\n",
    "  .setLabelCol(\"Price\")\n",
    "  .setFeaturesCol(\"scaledFeatures\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMaxMemoryInMB(512)\n",
    "  .setCacheNodeIds(true)\n",
    "\n",
    "rf.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res32: Array[String] = Array(Price, MethodOfSale, PropertyType, DistanceFromCBD, Rooms, Bathroom, Car, Landsize, Latitude, Longtitude, Suburb, Date, StreetName, loggedPrice)\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res33: Array[String] = Array(Price, MethodOfSale, PropertyType, DistanceFromCBD, Rooms, Bathroom, Car, Landsize, Latitude, Longtitude, Suburb, Date, StreetName, loggedPrice)\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define get_predictions Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.Predictor\n",
       "import org.apache.spark.ml.linalg.Vector\n",
       "import org.apache.spark.ml.PredictionModel\n",
       "import org.apache.spark.ml.Pipeline\n",
       "get_predictions: [R <: org.apache.spark.ml.Predictor[org.apache.spark.ml.linalg.Vector,R,M], M <: org.apache.spark.ml.PredictionModel[org.apache.spark.ml.linalg.Vector,M]](predictor: org.apache.spark.ml.Predictor[org.apache.spark.ml.linalg.Vector,R,M], train: org.apache.spark.sql.DataFrame, test: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Predictor\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.ml.PredictionModel\n",
    "import org.apache.spark.ml.Pipeline\n",
    "\n",
    "def get_predictions[R <: Predictor[Vector, R, M],\n",
    "                M <: PredictionModel[Vector, M]](\n",
    "    predictor: Predictor[Vector, R, M],\n",
    "    train: DataFrame, \n",
    "    test: DataFrame) = {\n",
    "    \n",
    "    val pipeline = new Pipeline()\n",
    "      .setStages(Array(suburbIndexer,\n",
    "                       streetNameIndexer,\n",
    "                       propertyTypeIndexer,\n",
    "                       methodOfSaleIndexer,\n",
    "                       allEncoder,\n",
    "                       assembler, \n",
    "                       scaler,\n",
    "                       predictor))\n",
    "     \n",
    "    val result =pipeline.fit(train).transform(test)\n",
    "    result\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rfPredictions: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 23 more fields]\n",
       "res34: rfPredictions.type = [Price: double, MethodOfSale: string ... 23 more fields]\n"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rfPredictions = time{get_predictions(rf, train, test)}\n",
    "rfPredictions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|   Price|prediction|\n",
      "+--------+----------+\n",
      "|185000.0|  607393.0|\n",
      "|286000.0|  637238.0|\n",
      "|288000.0|  501286.0|\n",
      "|288000.0|  701333.0|\n",
      "|291000.0|  526817.0|\n",
      "+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfPredictions.withColumn(\"prediction\", round($\"prediction\", 0)).select(\"Price\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|            Price|        prediction|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|             2548|              2548|\n",
      "|   mean|1160930.008634223|1147004.4470918612|\n",
      "| stddev|675320.2767043534| 386417.1674604188|\n",
      "|    min|         185000.0|495424.37769344856|\n",
      "|    max|        6370000.0|3293346.3098556255|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfPredictions.describe().select(\"summary\",\"Price\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assess_rf: (predictions: org.apache.spark.sql.DataFrame, metric: String)Unit\n"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def assess_rf ( predictions: DataFrame, metric: String) = {\n",
    "    val eval =  new RegressionEvaluator()\n",
    "       .setLabelCol(\"Price\")\n",
    "       .setPredictionCol(\"prediction\")\n",
    "       .setMetricName(metric)\n",
    "println(metric.toUpperCase()+\" on test data = \" + eval.evaluate(predictions))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 423798.832023332\n"
     ]
    }
   ],
   "source": [
    "assess_rf(rfPredictions,\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.6060234161269165\n"
     ]
    }
   ],
   "source": [
    "assess_rf(rfPredictions,\"r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Finding the Best Model (Parameter Tuning) by Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.Predictor\n",
       "import org.apache.spark.ml.linalg.Vector\n",
       "import org.apache.spark.ml.PredictionModel\n",
       "train_eval: [R <: org.apache.spark.ml.Predictor[org.apache.spark.ml.linalg.Vector,R,M], M <: org.apache.spark.ml.PredictionModel[org.apache.spark.ml.linalg.Vector,M]](predictor: org.apache.spark.ml.Predictor[org.apache.spark.ml.linalg.Vector,R,M], paramMap: Array[org.apache.spark.ml.param.ParamMap], train: org.apache.spark.sql.DataFrame, test: org.apache.spark.sql.DataFrame)org.apache.spark.ml.Model[_]\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Predictor\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.ml.PredictionModel\n",
    "\n",
    "\n",
    "\n",
    "def train_eval[R <: Predictor[Vector, R, M],\n",
    "               M <: PredictionModel[Vector, M]](\n",
    "    predictor: Predictor[Vector, R, M],\n",
    "    paramMap: Array[ParamMap],\n",
    "    train: DataFrame, \n",
    "    test: DataFrame) = {\n",
    "\n",
    "    val pipeline = new Pipeline()\n",
    "      .setStages(Array(\n",
    "          suburbIndexer,\n",
    "          streetNameIndexer,\n",
    "          propertyTypeIndexer,\n",
    "          methodOfSaleIndexer,\n",
    "          allEncoder,\n",
    "          assembler, \n",
    "          scaler,\n",
    "          predictor))\n",
    "    \n",
    "    val cv = new CrossValidator()\n",
    "        .setEstimator(pipeline)\n",
    "        .setEvaluator(new RegressionEvaluator()\n",
    "        .setLabelCol(\"Price\")\n",
    "        .setPredictionCol(\"prediction\")\n",
    "        .setMetricName(\"rmse\"))\n",
    "        .setEstimatorParamMaps(paramMap)\n",
    "        .setNumFolds(5)\n",
    "        .setParallelism(2)\n",
    "\n",
    "    val cvModel = cv.fit(train)\n",
    "    val predictions = cvModel.transform(test)\n",
    "    \n",
    "    predictions.cache()\n",
    "   \n",
    "    val bestModel = cvModel.bestModel\n",
    "    \n",
    "    println(bestModel.extractParamMap)\n",
    "    \n",
    "    bestModel\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\n",
      "}\n",
      "Model was executed 3994 s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.RandomForestRegressor\n",
       "numTrees: Seq[Int] = List(5, 10, 20, 30, 50, 100)\n",
       "maxBins: Seq[Int] = List(32, 50, 100)\n",
       "maxDepth: Seq[Int] = List(2, 3, 5)\n",
       "rf: org.apache.spark.ml.regression.RandomForestRegressor = rfr_fe3daf09aef5\n",
       "rfParamMap: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\trfr_fe3daf09aef5-maxBins: 32,\n",
       "\trfr_fe3daf09aef5-maxDepth: 2,\n",
       "\trfr_fe3daf09aef5-numTrees: 5\n",
       "}, {\n",
       "\trfr_fe3daf09aef5-maxBins: 32,\n",
       "\trfr_fe3daf09aef5-maxDepth: 2,\n",
       "\trfr_fe3daf09aef5-numTrees: 10\n",
       "}, {\n",
       "\trfr_fe3daf09aef5-maxBins: 32,\n",
       "\trfr_fe3daf09aef5-maxDepth: 2,\n",
       "\trfr_fe3daf09aef5-numTrees: 20\n",
       "}, {\n",
       "\trfr_fe3daf09aef5-maxBins: 32,\n",
       "\trfr_fe3daf09aef5-maxDepth: 2,\n",
       "\trfr_fe3daf09aef5-numTrees: 30\n",
       "}, {\n",
       "\trfr_fe3daf09aef5-maxBins: 32,\n",
       "\trfr_fe3daf09aef5-maxDepth: 2,\n",
       "\trfr_fe3daf09aef5-num..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.RandomForestRegressor\n",
    "\n",
    "// Models hyperparameters\n",
    "val numTrees = Seq(5,10,20,30,50,100)\n",
    "val maxBins = Seq(32,50,100)\n",
    "val maxDepth = Seq(2,3,5)\n",
    "//val featureSubsetStrategy = Seq(\"sqrt\",\"onethird\")\n",
    "\n",
    "val rf = new RandomForestRegressor()\n",
    "  .setSeed(36L)\n",
    "  .setLabelCol(\"Price\")\n",
    "  .setFeaturesCol(\"scaledFeatures\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setImpurity(\"variance\")\n",
    "  .setMaxMemoryInMB(512)\n",
    "  .setCacheNodeIds(true)\n",
    "\n",
    "\n",
    "val rfParamMap = new ParamGridBuilder()\n",
    "  .addGrid(rf.numTrees, numTrees)\n",
    "  .addGrid(rf.maxDepth, maxDepth)\n",
    "  .addGrid(rf.maxBins, maxBins)\n",
    "  .build()\n",
    "\n",
    "val tStart = System.nanoTime()\n",
    "val best_model = train_eval(rf, rfParamMap, train, test)\n",
    "val tEnd = System.nanoTime()\n",
    "\n",
    "print(\"Model was executed \"\n",
    "      + getExecutionTime(tStart/1000000,tEnd/1000000)+\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RF params = {\n",
      "\trfr_fe3daf09aef5-cacheNodeIds: true,\n",
      "\trfr_fe3daf09aef5-checkpointInterval: 10,\n",
      "\trfr_fe3daf09aef5-featureSubsetStrategy: auto,\n",
      "\trfr_fe3daf09aef5-featuresCol: scaledFeatures,\n",
      "\trfr_fe3daf09aef5-impurity: variance,\n",
      "\trfr_fe3daf09aef5-labelCol: Price,\n",
      "\trfr_fe3daf09aef5-maxBins: 100,\n",
      "\trfr_fe3daf09aef5-maxDepth: 5,\n",
      "\trfr_fe3daf09aef5-maxMemoryInMB: 512,\n",
      "\trfr_fe3daf09aef5-minInfoGain: 0.0,\n",
      "\trfr_fe3daf09aef5-minInstancesPerNode: 1,\n",
      "\trfr_fe3daf09aef5-numTrees: 20,\n",
      "\trfr_fe3daf09aef5-predictionCol: prediction,\n",
      "\trfr_fe3daf09aef5-seed: 36,\n",
      "\trfr_fe3daf09aef5-subsamplingRate: 1.0\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.RandomForestRegressionModel\n",
       "bestPipelineModel: org.apache.spark.ml.PipelineModel = pipeline_5d2eb89b2887\n",
       "stages: Array[org.apache.spark.ml.Transformer] = Array(strIdx_3463fa11bb00, strIdx_cddfe89225ef, strIdx_03dbaa739beb, strIdx_c40487103e32, oneHotEncoder_32532d9cc924, vecAssembler_3107d3d55de1, stdScal_7ca98adda80b, RandomForestRegressionModel (uid=rfr_fe3daf09aef5) with 20 trees)\n",
       "bestRFModel: org.apache.spark.ml.regression.RandomForestRegressionModel = RandomForestRegressionModel (uid=rfr_fe3daf09aef5) with 20 trees\n"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.RandomForestRegressionModel\n",
    "\n",
    "val bestPipelineModel = best_model.asInstanceOf[PipelineModel]\n",
    "\n",
    "val stages = bestPipelineModel.stages\n",
    "for (i <- stages) println\n",
    "\n",
    "val bestRFModel = stages.last.asInstanceOf[RandomForestRegressionModel]\n",
    "\n",
    "println(\"RF params = \" + bestRFModel.extractParamMap())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 11 s\n",
      "2020-06-08 17:27:28,147 WARN  [Thread-4] execution.CacheManager (Logging.scala:logWarning(66)) - Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "seed: Int = 5043\n",
       "rf_best: org.apache.spark.ml.regression.RandomForestRegressor = rfr_c62109dd9569\n",
       "rf_best_Predictions: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale: string ... 23 more fields]\n",
       "res41: rfPredictions.type = [Price: double, MethodOfSale: string ... 23 more fields]\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val seed = 5043\n",
    "val rf_best = new RandomForestRegressor()\n",
    "  .setSeed(seed)\n",
    "  .setLabelCol(\"Price\")\n",
    "  .setNumTrees(bestRFModel.getNumTrees)\n",
    "  .setMaxDepth(bestRFModel.getMaxDepth)\n",
    "  .setMaxBins(bestRFModel.getMaxBins)\n",
    "  .setMaxMemoryInMB(512)\n",
    "  .setCacheNodeIds(true)\n",
    "\n",
    "val rf_best_Predictions = time{get_predictions(rf_best, train, test)}\n",
    "rfPredictions.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Metrics on the Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 422428.83685602905\n"
     ]
    }
   ],
   "source": [
    "assess_rf(rf_best_Predictions,\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.6085664793401491\n"
     ]
    }
   ],
   "source": [
    "assess_rf(rf_best_Predictions,\"r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Apply K-means Model  \n",
    "\n",
    "Unsupervised learning problem. To find opimal number of clusters run many models with differnet numer of clusters. When the number of clusters increses the differences between clusters gets smaller while the differences between points inside clusters increase as well. Optimally, WCSSE -  Within Set Sum of Squared Errors, should be as small as possible, while Slhouette coefficient lies in the interval [-1,1] and is a measure of cohesion inside the clusters and separation between the clusters should get as close to 1 as possible.\n",
    "\n",
    "* WSSSE -  Within Set Sum of Squared Errors\n",
    "* Slhouette coefficient  for a data point is  $(b-a)/max(a,b)$, where $a$ - measure of cohesion (mean intra-cluster distance), b - measure of separarion (the distance between a sample and the nearest cluster that the sample is not a part of)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting & Hashing \n",
    "\n",
    "Because K-Means requires to include the \"Price\" feature to create the clusters in the training data but to exclude from the test data for accuracy, new splitting and hashing need to be utilised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indexers: Array[org.apache.spark.ml.feature.StringIndexer] = Array(strIdx_ae16616eb85a, strIdx_ddb21bc2e7e5, strIdx_ffc6fbc962c7, strIdx_c9e962db593b)\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_caf1994a0a4b\n",
       "vectorise: (data: org.apache.spark.sql.DataFrame, col1: String, col2: String)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val indexers = Array(\"Suburb\",\"StreetName\",\"MethodOfSale\",\"PropertyType\").map { colName =>\n",
    "  new StringIndexer()\n",
    "    .setInputCol(colName)\n",
    "    .setOutputCol(colName + \"_Ind\")\n",
    "}\n",
    "\n",
    "// Create a pipeline which exacutes the indexing of the string type features\n",
    "val pipeline = new Pipeline().setStages(indexers)\n",
    "\n",
    "// Create a Vector of the Features to be used for Training & Testing\n",
    "def vectorise(data: DataFrame, col1:String, col2:String) = {\n",
    "    \n",
    "    val assembler = new VectorAssembler()\n",
    "        .setInputCols(data.drop(col1,col2).columns)\n",
    "        .setOutputCol(\"features\")\n",
    "    \n",
    "    (assembler.transform(data))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Price: double (nullable = true)\n",
      " |-- MethodOfSale_Ind: double (nullable = false)\n",
      " |-- PropertyType_Ind: double (nullable = false)\n",
      " |-- DistanceFromCBD: double (nullable = true)\n",
      " |-- Rooms: integer (nullable = true)\n",
      " |-- Bathroom: integer (nullable = true)\n",
      " |-- Car: integer (nullable = true)\n",
      " |-- Landsize: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Date: long (nullable = true)\n",
      " |-- Suburb_Ind: double (nullable = false)\n",
      " |-- StreetName_Ind: double (nullable = false)\n",
      " |-- loggedPrice: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "strIndex_train: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale_Ind: double ... 11 more fields]\n",
       "kmeans_train: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale_Ind: double ... 12 more fields]\n"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Training Data Vectorising and Reordering the Columns\n",
    "val strIndex_train = pipeline.fit(train).transform(train).drop(\"StreetName\",\n",
    "                                                               \"Suburb\",\n",
    "                                                               \"MethodOfSale\",\n",
    "                                                               \"PropertyType\"\n",
    "                                                              ).select(\"Price\",\n",
    "                                                                       \"MethodOfSale_Ind\",\n",
    "                                                                       \"PropertyType_Ind\",\n",
    "                                                                       \"DistanceFromCBD\",\n",
    "                                                                       \"Rooms\",\n",
    "                                                                       \"Bathroom\",\n",
    "                                                                       \"Car\",\n",
    "                                                                       \"Landsize\", \n",
    "                                                                       \"Latitude\", \n",
    "                                                                       \"Date\", \n",
    "                                                                       \"Suburb_Ind\", \n",
    "                                                                       \"StreetName_Ind\",\n",
    "                                                                       \"loggedPrice\")\n",
    "\n",
    "val kmeans_train = vectorise(strIndex_train,\"Price\",\"\")\n",
    "\n",
    "kmeans_train.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Price: double (nullable = true)\n",
      " |-- MethodOfSale_Ind: double (nullable = false)\n",
      " |-- PropertyType_Ind: double (nullable = false)\n",
      " |-- DistanceFromCBD: double (nullable = true)\n",
      " |-- Rooms: integer (nullable = true)\n",
      " |-- Bathroom: integer (nullable = true)\n",
      " |-- Car: integer (nullable = true)\n",
      " |-- Landsize: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Date: long (nullable = true)\n",
      " |-- Suburb_Ind: double (nullable = false)\n",
      " |-- StreetName_Ind: double (nullable = false)\n",
      " |-- loggedPrice: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "strIndex_test: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale_Ind: double ... 11 more fields]\n",
       "kmeans_test: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale_Ind: double ... 12 more fields]\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Test Data Vectorising and Reordering the Columns\n",
    "val strIndex_test = pipeline.fit(test).transform(test).drop(\"StreetName\",\n",
    "                                                               \"Suburb\",\n",
    "                                                               \"MethodOfSale\",\n",
    "                                                               \"PropertyType\"\n",
    "                                                              ).select(\"Price\",\n",
    "                                                                       \"MethodOfSale_Ind\",\n",
    "                                                                       \"PropertyType_Ind\",\n",
    "                                                                       \"DistanceFromCBD\",\n",
    "                                                                       \"Rooms\",\n",
    "                                                                       \"Bathroom\",\n",
    "                                                                       \"Car\",\n",
    "                                                                       \"Landsize\", \n",
    "                                                                       \"Latitude\", \n",
    "                                                                       \"Date\", \n",
    "                                                                       \"Suburb_Ind\", \n",
    "                                                                       \"StreetName_Ind\",\n",
    "                                                                       \"loggedPrice\")\n",
    "\n",
    "val kmeans_test = vectorise(strIndex_test,\"Price\",\"loggedPrice\")\n",
    "\n",
    "kmeans_test.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was executed 1"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.clustering.{KMeans, KMeansModel}\n",
       "startTimeMillis: Long = 1591654808866\n",
       "count: Long = 10195\n",
       "k: Int = 50\n",
       "kmeans: org.apache.spark.ml.clustering.KMeans = kmeans_25f565326ad5\n",
       "model: org.apache.spark.ml.clustering.KMeansModel = kmeans_25f565326ad5\n",
       "endTimeMillis: Long = 1591654810624\n"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.clustering.{KMeans,KMeansModel}\n",
    "\n",
    "val startTimeMillis = System.currentTimeMillis()\n",
    "\n",
    "// Get the count on training data\n",
    "val count = kmeans_train.count()\n",
    "\n",
    "// Get the number of clusters by deciding on the amount of properties to have in each cluster\n",
    "val k = (count/200).toInt\n",
    "\n",
    "// Trains a k-means model.\n",
    "val kmeans = new KMeans()\n",
    "    .setK(k)\n",
    "    .setSeed(7L) // Random seed\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setPredictionCol(\"prediction\")\n",
    "\n",
    "// Define the Training Model of K-Means\n",
    "val model = kmeans.fit(kmeans_train.select(\"features\"))\n",
    "\n",
    "// Print runtime\n",
    "val endTimeMillis = System.currentTimeMillis()\n",
    "\n",
    "print(\"Model was executed \"\n",
    "      + getExecutionTime(startTimeMillis,endTimeMillis))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "Manually find the closest cluster based on its Euclidean distance.\n",
    "Once found, assign the cluster's Price as a prediction and then test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.clustering.{KMeans,KMeansModel}\n",
    "\n",
    "val kmeans = new KMeans().setSeed(5043L)\n",
    "                         .setPredictionCol(\"cluster\")\n",
    "                         .setFeaturesCol(\"scaledFeatures\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import math._\n",
       "import org.apache.spark.ml.linalg.Vector\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "ecldnDist: (feature: org.apache.spark.ml.linalg.Vector)Double\n",
       "distance: org.apache.spark.ml.linalg.Vector => Double = <function1>\n",
       "DistFromCluster: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math._\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "def ecldnDist(feature:Vector):Double = {\n",
    "    var dist = 1000000000000000000000.0 // Initialise Distance variable, with a high value to ensure first result is lesser\n",
    "    var price:Double = 0.0 // Initialise the predicted Price Variable\n",
    "    \n",
    "    // Iterate though all Clusters Centres for this Row\n",
    "    for (cluster <- model.clusterCenters){\n",
    "\n",
    "        var cl_clean = Vectors.dense(cluster.toArray.slice(0,11)) // Drops the price from the clusters\n",
    "\n",
    "        // Get the Euclidean Distance of Row's Features Vector & Cluster Vector.\n",
    "        var r_dist = sqrt(Vectors.sqdist(feature,cl_clean))\n",
    "\n",
    "        // Check if calculated distanct is less than the previous one.\n",
    "        if (r_dist < dist) {dist = r_dist // Assigns Smaller Distance\n",
    "                            price = cluster.toArray.apply(11)} // Assigns Cluster Price of Current Smallest Distance     \n",
    "    }\n",
    "    return price // Returns the Price from the Custer with the smallest distance from this row.\n",
    "}\n",
    "\n",
    "// Creates the Input and Calculation for Distance\n",
    "val distance = (feature:Vector) => {ecldnDist(feature)}\n",
    "// Creates the User Defined Function from the Distance calcuation\n",
    "val DistFromCluster = udf(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+------------------+\n",
      "|   Price|        Prediction|       loggedPrice|  loggedPrediction|\n",
      "+--------+------------------+------------------+------------------+\n",
      "|185000.0| 973533.9837894678|12.128111104060462|13.788688012059737|\n",
      "|286000.0| 870818.8085811978| 12.56374708980199|13.677189207306787|\n",
      "|288000.0| 1151399.988978017|12.570715759118084|13.956489141651167|\n",
      "|288000.0|1031081.5555729611|12.570715759118084|13.846118863239127|\n",
      "|291000.0|1097221.8773479369|12.581078546153629|13.908291977099386|\n",
      "|302500.0| 997637.2812438598|12.619836556453032| 13.81314504358379|\n",
      "|305000.0| 997637.2812438598|12.628067055589549| 13.81314504358379|\n",
      "|312000.0|1061109.2453129117| 12.65075846679162|13.874825376775295|\n",
      "|316000.0| 909345.7110506814| 12.66349749256905|13.720480621043993|\n",
      "|325000.0|1077296.5286158721|12.691580461311874|13.889965246576779|\n",
      "|326500.0|1081608.0443909555|12.696185227698622|13.893959421734817|\n",
      "|327000.0|1041194.2493288394|12.697715449879391|13.855878928968623|\n",
      "|330000.0|1102483.5609930311|12.706847933442663|13.913075975528056|\n",
      "|330000.0| 990170.8466992012|12.706847933442663|  13.8056327796453|\n",
      "|347500.0| 974641.1163914865|12.758519943986984|13.789824596467474|\n",
      "|352000.0|1102483.5609930311|12.771386454580234|13.913075975528056|\n",
      "|354000.0| 937847.1351081888|12.777052192115912| 13.75134224573966|\n",
      "|355000.0| 997637.2812438598|12.779873068457553| 13.81314504358379|\n",
      "|355000.0| 990170.8466992012|12.779873068457553|  13.8056327796453|\n",
      "|360000.0|1059870.7624445094|12.793859310432293| 13.87365753643297|\n",
      "+--------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "kmeans_predict: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale_Ind: double ... 14 more fields]\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Creates a new DataFrame from the test DataFrame\n",
    "val kmeans_predict = kmeans_test.withColumn(\"loggedPrediction\",DistFromCluster(col(\"features\")))\n",
    "                                .withColumn(\"Prediction\", exp(col(\"loggedPrediction\")))\n",
    "\n",
    "// Display acatual and predicted Price\n",
    "kmeans_predict.select(\"Price\",\"Prediction\",\"loggedPrice\",\"loggedPrediction\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the model: choosing number of clusters\n",
    "\n",
    "\n",
    "Evaluate the quality of clustering by \"elbowing\" the Within Set Sum of Squared Errors (WSSSE) graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assess_kmeans: (predictions: org.apache.spark.sql.DataFrame, metric: String, Label: String, Predicted: String)Unit\n"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// define an evaluator for the cross validation\n",
    "def assess_kmeans ( predictions: DataFrame, metric: String, Label:String, Predicted:String) = {\n",
    "    val eval =  new RegressionEvaluator()\n",
    "       .setLabelCol(Label)\n",
    "       .setPredictionCol(Predicted)\n",
    "       .setMetricName(metric)\n",
    "println(metric.toUpperCase()\n",
    "        +\" on test data = \" + eval.evaluate(predictions))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 687448.5690973068\n",
      "R2 on test data = -0.036648023222835446\n"
     ]
    }
   ],
   "source": [
    "assess_kmeans(kmeans_predict,\"rmse\", \"Price\", \"Prediction\")\n",
    "assess_kmeans(kmeans_predict,\"r2\", \"Price\", \"Prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 0.4963851651071106\n",
      "R2 on test data = 0.014772275830187365\n"
     ]
    }
   ],
   "source": [
    "// Evaluating model on Logged Prices\n",
    "assess_kmeans(kmeans_predict,\"rmse\", \"loggedPrice\", \"loggedPrediction\")\n",
    "assess_kmeans(kmeans_predict,\"r2\", \"loggedPrice\", \"loggedPrediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions: org.apache.spark.sql.DataFrame = [Price: double, MethodOfSale_Ind: double ... 13 more fields]\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Make clustering predictions\n",
    "val predictions = model.transform(kmeans_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSSSE error 8.296803634448306E12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WSSSE: Double = 8.296803634448306E12\n"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Within Set Sum of Squared Errors\n",
    "val WSSSE = model.computeCost(kmeans_train)\n",
    "\n",
    "println(\"WSSSE error \" + WSSSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.9044180211036867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.evaluation.ClusteringEvaluator\n",
       "evaluator: org.apache.spark.ml.evaluation.ClusteringEvaluator = cluEval_78d7eff955a4\n",
       "silhouette: Double = 0.9044180211036867\n"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.ClusteringEvaluator\n",
    "\n",
    "// Evaluate clustering by computing Silhouette score\n",
    "val evaluator = new ClusteringEvaluator()\n",
    "\n",
    "val silhouette = evaluator.evaluate(predictions)\n",
    "println(s\"Silhouette with squared euclidean distance = $silhouette\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimise K value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "best_WSSSE: scala.collection.mutable.Map[Int,Double] = Map(92 -> 7.001114449439612E12, 101 -> 6.423539686884444E12, 254 -> 5.99411879365806E11, 113 -> 4.913530624124615E12, 1019 -> 4.873542011968228E10, 59 -> 8.2858933581569375E12, 50 -> 8.296803634448306E12, 35 -> 1.937505399002961E13, 53 -> 9.215747961377908E12, 44 -> 1.5307196910916209E13, 56 -> 7.375377665400225E12, 169 -> 6.040809283633082E11, 127 -> 1.273146526643202E12, 46 -> 1.5592662285355186E13, 145 -> 6.072583098837406E11, 67 -> 7.625075500775409E12, 40 -> 1.6585845734998344E13, 339 -> 5.980388033158956E11, 37 -> 1.8038315008069004E13, 509 -> 5.970080507454269E11, 78 -> 7.014796624907247E12, 63 -> 7.04193640482158E12, 72 -> 7.624576680922204E12, 36 -> 1.8750028936776793E13, 84 -> 7.006496694033419E12, 48 -> 1.5261873523995467..."
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Initialise the Map\n",
    "var best_WSSSE = scala.collection.mutable.Map[Int,Double]()\n",
    "var best_Silh = scala.collection.mutable.Map[Int,Double]()\n",
    "\n",
    "for (p <- 10 to 300 by 10){\n",
    "\n",
    "    // Get the number of clusters by deciding on the amount of data points to have in each cluster\n",
    "    val k = (kmeans_training.count()/p).toInt\n",
    "    \n",
    "    // Trains a k-means model.\n",
    "    val kmeans = new KMeans()\n",
    "    .setK(k)\n",
    "    .setSeed(7L) // Random seed\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setPredictionCol(\"prediction\")\n",
    "\n",
    "    // Define the Training Model of K-Means\n",
    "    val model = kmeans.fit(kmeans_train.select(\"features\"))\n",
    "    // Make Clustering predictions\n",
    "    val predictions = model.transform(kmeans_train)\n",
    "    \n",
    "    // Within Set Sum of Squared Errors\n",
    "    val WSSSE = model.computeCost(kmeans_train)\n",
    "    // Append the p value (property count per cluster) and WSSSE in the Map\n",
    "    best_WSSSE += k -> WSSSE\n",
    "    // Clustering Silhouette\n",
    "    val silhouette = evaluator.evaluate(predictions)\n",
    "    // Append the p value (property count per cluster) and Silhouette Score in the Map\n",
    "    best_Silh += k -> silhouette\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_best_wssse: Int = 1019\n"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Optimal number of clasters minimising WSSSE metircs\n",
    "val k_best_wssse = best_WSSSE.minBy(_._2)._1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_best_silh: Int = 50\n"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Optimal number of clusters maximising Silhouette \n",
    "val k_best_silh = best_Silh.maxBy(_._2)._1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res83: Double = 4.873542011968228E10\n"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Best wssse\n",
    " best_WSSSE.minBy(_._2)._2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res85: Double = 4780325.661567659\n"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.873542011968228E10/10195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pnt_count: Int = 10195\n"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pnt_count = kmeans_train.count().toInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res81: Int = 10\n"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Number of observations per cluster minimising WSSSE metircs\n",
    "pnt_count/k_best_wssse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res82: Int = 203\n"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Number of observations per cluster maximising the Silhouette coefficient\n",
    "pnt_count/k_best_silh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res84: Double = 0.9044180211104262\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Best Silhouette coefficient\n",
    "best_Silh.maxBy(_._2)._2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above the the number of observations per cluster which minimises the WSSSE is 10. It makes sense as the less values are within a cluster the more accurate is a prediction\n",
    "\n",
    "However, as the Silhouette coefficient indicates how well the data fits with its clusters it suggests 230 is a better number of observations per cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Apache Spark (n.d.). _Spark ML Programming Guide._ Retrieved from https://spark.apache.org/docs/1.2.2/ml-guide.html\n",
    "\n",
    "Bahadoor N., (2020). _Spark tutorials_ Retrieved from https://allaboutscala.com/big-data/spark/\n",
    "Gorczynski M. (2017). _Introduction to machine learning with spark and mllib (dataframe API)._ Retrieved from https://scalac.io/scala-spark-ml-machine-learning-introduction/\n",
    "\n",
    "Hydrospheredata (2020). Program creek. Scala Code Examples. Scaler Retrieved from https://www.programcreek.com/scala/org.apache.spark.ml.feature.StandardScaler\n",
    "\n",
    "Jen G. (2020) _FeatureHasher_. Retrieved from https://george-jen.gitbook.io/data-science-and-apache-spark/featurehasher\n",
    "\n",
    "Johnson S (2019). _From sckit-learn to Spark ML._ Retrieved from https://towardsdatascience.com/from-scikit-learn-to-spark-ml-f2886fb46852\n",
    "\n",
    "Johnson S (2019). _Housing Prices - Spark ML Project_ Retrieved from https://github.com/scottdjohnson/HousingPricePredictions/blob/master/HousingPrices-SparkML.ipynb\n",
    "\n",
    "Masri A. (2019). _FeatureTransformation. Retrieved from\n",
    "https://towardsdatascience.com/apache-spark-mllib-tutorial-7aba8a1dce6e\n",
    "\n",
    "Poddutur S. (). _Distribution of Executors, Cores and Memory for a Spark Application running in Yarn:_ Retrieved from https://spoddutur.github.io/spark-notes/distribution_of_executors_cores_and_memory_for_spark_application.html \n",
    "\n",
    "Rai D.,(2018) _Feature Engineering in pyspark — Part I._ Retrieved from https://medium.com/@dhiraj.p.rai/essentials-of-feature-engineering-in-pyspark-part-i-76a57680a85\n",
    "\n",
    "Sarkar A. (2017). _Learning Spark SQL. Implementing a Spark ML clustering model._ Packt Publishing.\n",
    "\n",
    "Scala Doc (n.d.) Retrieved from https://docs.scala-lang.org\n",
    "\n",
    "\n",
    "(2019) _Random Forest Classifier with Apache Spark_ Retireved from https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "\n",
    "Wagle M.(2020) _Predicting House Prices using Machine Learning_. Retrieved from https://medium.com/@manilwagle/predicting-house-prices-using-machine-learning-cab0b82cd3f\n",
    "\n",
    "\n",
    "Zecevic P., Bonaci M. (2020) _Spark in Action_ Retireved from https://livebook.manning.com/book/spark-in-action/about-this-book/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
